import logging
import pathlib
from huggingface_hub import snapshot_download
from modelscope.pipelines import pipeline
from modelscope.outputs import OutputKeys
from telegram import __version__ as TG_VER
from telegram import InputFile, Update, ForceReply
from telegram.ext import (
    Application,
    CommandHandler,
    ContextTypes,
    MessageHandler,
    filters,
)

# Enable logging
logging.basicConfig(
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s", level=logging.INFO
)
logger = logging.getLogger(__name__)

# Download the model from Hugging Face and set up the pipeline
model_dir = pathlib.Path("weights")
snapshot_download(
    "damo-vilab/modelscope-damo-text-to-video-synthesis",
    repo_type="model",
    cache_dir=model_dir,
)

pipe = pipeline("text-to-video-synthesis", model_dir.as_posix())

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user = update.effective_user
    await update.message.reply_html(
        rf"Hi {user.mention_html()}!",
        reply_markup=ForceReply(selective=True),
    )

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.message.reply_text("Help!")

async def echo(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    # Get the text from the user's message
    test_text = {"text": update.message.text}

    # Use the pipeline to generate a video
    output_video_path = pipe(test_text)[OutputKeys.OUTPUT_VIDEO]

    # Send the video back to the user
    with open(output_video_path, "rb") as video_file:
        await update.message.reply_video(video=InputFile(video_file))

def main() -> None:
    application = Application.builder().token("5927967694:AAHrAcStHvN-nthBrYti_sMg2B5NGuhiz5c").build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, echo))

    application.run_polling()

if __name__ == "__main__":
    main()
